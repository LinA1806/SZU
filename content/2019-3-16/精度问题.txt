2019.3.16
------------------------------------------------------------



题目来源：今天看书看到 1+1/2+1/3+.....+1/100 求和的问题，然后突然想起上年某位考上的师兄说面试的时候面试官就问他这个问题。
------------------------------------------------------------



问题描述：叫你写一个程序，求1+1/2+1/3+.....+1/100的和。
------------------------------------------------------------



我的分析：
我先是写了这端代码如下：
double method1(){
    int i;
    double sum = 0.0;
    for(i=1;i<=100;i++){
        sum += (double)1/i;
    }
    return sum;
}

再写了一段：
double method2(){
    int i;
    double sum = 0.0;
    for(i=100;i>=1;i++){
        sum += (double)1/i;
    }
    return sum;
}

然后测试：
int main()
{
    double m1 = method1();
    double m2 = method2();
    printf("%.2f\n",m1);
    printf("%.2f\n",m2);
    return 0;
}

结果 m1 = 5.19 ; m2 = 16.98

	
结果令我很惊讶，我有点不相信，但是代码好像也没错，然后上网查了一下：发现别人是1+1/2+...+1/100000,我也试了 结果反而 m1 > m2。？？？无解


对于1加到100的:
顺着加会导致大数吃小数的问题，好像数值分析的课程也说过这个问题。
在计算机中，因为存储一个数只有n位，如果一个数很大22222222，一个数很小1.88888888，加起来是22222223.88888888，
在内存中n为把22222223.88888888放下，C语言应该是IEEE754,小数会跳到最前面，而后面的尾数会没了。
导致的结果是误差比1.88888888（被加数）还要大。

所以应该避免大数加小数：
网上查到，应该*避免很大的数做分母；*应该避免不接近的两个数相加（言外之意：两个数越解决，相加越精确）




